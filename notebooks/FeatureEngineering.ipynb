{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0X31zgSxU5mb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gc\n",
        "\n",
        "# Carga de datos\n",
        "pd.read_csv(\"data/raw/sales_train.csv\")\n",
        "test  = pd.read_csv(\"data/raw/test.csv\")\n",
        "\n",
        "train.columns = train.columns.str.strip()\n",
        "test.columns  = test.columns.str.strip()\n",
        "\n",
        "# Tipos numéricos para evitar problemas al agrupar\n",
        "train[\"date_block_num\"] = pd.to_numeric(train[\"date_block_num\"], errors=\"coerce\")\n",
        "train[\"shop_id\"]        = pd.to_numeric(train[\"shop_id\"], errors=\"coerce\")\n",
        "train[\"item_id\"]        = pd.to_numeric(train[\"item_id\"], errors=\"coerce\")\n",
        "train[\"item_price\"]     = pd.to_numeric(train[\"item_price\"], errors=\"coerce\")\n",
        "train[\"item_cnt_day\"]   = pd.to_numeric(train[\"item_cnt_day\"], errors=\"coerce\")\n",
        "\n",
        "test[\"ID\"]      = pd.to_numeric(test[\"ID\"], errors=\"coerce\")\n",
        "test[\"shop_id\"] = pd.to_numeric(test[\"shop_id\"], errors=\"coerce\")\n",
        "test[\"item_id\"] = pd.to_numeric(test[\"item_id\"], errors=\"coerce\")\n",
        "\n",
        "# Eliminamos filas incompletas en columnas clave\n",
        "train = train.dropna(subset=[\"date_block_num\",\"shop_id\",\"item_id\",\"item_price\",\"item_cnt_day\"])\n",
        "test  = test.dropna(subset=[\"ID\",\"shop_id\",\"item_id\"])\n",
        "\n",
        "# Dtypes compactos (ahorra memoria)\n",
        "train[\"date_block_num\"] = train[\"date_block_num\"].astype(np.int16)\n",
        "train[\"shop_id\"] = train[\"shop_id\"].astype(np.int16)\n",
        "train[\"item_id\"] = train[\"item_id\"].astype(np.int16)\n",
        "\n",
        "test[\"ID\"] = test[\"ID\"].astype(np.int32)\n",
        "test[\"shop_id\"] = test[\"shop_id\"].astype(np.int16)\n",
        "test[\"item_id\"] = test[\"item_id\"].astype(np.int16)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "KrBF6tOTU5oq"
      },
      "outputs": [],
      "source": [
        "# Tratamiento mínimo: precios inválidos y extremos muy raros\n",
        "# Es importante para que el modelo no aprenda cosas inconsistentes o dominadas por outliers\n",
        "train = train[train[\"item_price\"] >= 0]\n",
        "train = train[train[\"item_price\"] < 100000]\n",
        "train = train[(train[\"item_cnt_day\"] > -1000) & (train[\"item_cnt_day\"] < 1000)]\n",
        "\n",
        "# Agregación mensual: el objetivo del reto es predecir demanda mensual por (tienda, producto)\n",
        "monthly = (\n",
        "    train.groupby([\"date_block_num\",\"shop_id\",\"item_id\"], as_index=False)\n",
        "         .agg(item_cnt_month=(\"item_cnt_day\",\"sum\"),\n",
        "              price_mean=(\"item_price\",\"mean\"))\n",
        ")\n",
        "\n",
        "# Clipping del target al rango típico del reto (evita que pocos picos dominen el entrenamiento)\n",
        "monthly[\"item_cnt_month\"] = monthly[\"item_cnt_month\"].clip(0, 20).astype(np.float32)\n",
        "monthly[\"price_mean\"] = monthly[\"price_mean\"].astype(np.float32)\n",
        "\n",
        "max_block  = int(monthly[\"date_block_num\"].max())   # último mes con etiqueta\n",
        "test_block = max_block + 1                          # mes objetivo\n",
        "\n",
        "# Agregados globales/item/shop con shift de 1 mes para evitar leakage\n",
        "# La idea es que el mes t use información calculada hasta t-1\n",
        "global_agg = (\n",
        "    monthly.groupby(\"date_block_num\", as_index=False)\n",
        "           .agg(global_mean=(\"item_cnt_month\",\"mean\"),\n",
        "                global_sum=(\"item_cnt_month\",\"sum\"),\n",
        "                global_pairs=(\"item_cnt_month\",\"size\"))\n",
        ")\n",
        "global_agg[\"date_block_num\"] = (global_agg[\"date_block_num\"] + 1).astype(np.int16)\n",
        "\n",
        "item_agg = (\n",
        "    monthly.groupby([\"date_block_num\",\"item_id\"], as_index=False)\n",
        "           .agg(item_mean=(\"item_cnt_month\",\"mean\"),\n",
        "                item_shops=(\"shop_id\",\"nunique\"),\n",
        "                item_price_mean=(\"price_mean\",\"mean\"))\n",
        ")\n",
        "item_agg[\"date_block_num\"] = (item_agg[\"date_block_num\"] + 1).astype(np.int16)\n",
        "\n",
        "shop_agg = (\n",
        "    monthly.groupby([\"date_block_num\",\"shop_id\"], as_index=False)\n",
        "           .agg(shop_mean=(\"item_cnt_month\",\"mean\"),\n",
        "                shop_items=(\"item_id\",\"nunique\"))\n",
        ")\n",
        "shop_agg[\"date_block_num\"] = (shop_agg[\"date_block_num\"] + 1).astype(np.int16)\n",
        "\n",
        "# Panel denso: incluimos todos los meses para los pares del test\n",
        "# Esto es clave para capturar ceros “reales” (meses donde no hubo venta)\n",
        "test_pairs = test[[\"shop_id\",\"item_id\"]].drop_duplicates()\n",
        "n_pairs = len(test_pairs)\n",
        "\n",
        "months = np.arange(0, test_block + 1, dtype=np.int16)\n",
        "n_months = len(months)\n",
        "\n",
        "panel = pd.DataFrame({\n",
        "    \"date_block_num\": np.tile(months, n_pairs).astype(np.int16),\n",
        "    \"shop_id\": np.repeat(test_pairs[\"shop_id\"].values, n_months).astype(np.int16),\n",
        "    \"item_id\": np.repeat(test_pairs[\"item_id\"].values, n_months).astype(np.int16),\n",
        "})\n",
        "\n",
        "# Unimos el target mensual; si no hay registro, la venta mensual es 0\n",
        "panel = panel.merge(\n",
        "    monthly[[\"date_block_num\",\"shop_id\",\"item_id\",\"item_cnt_month\",\"price_mean\"]],\n",
        "    on=[\"date_block_num\",\"shop_id\",\"item_id\"],\n",
        "    how=\"left\"\n",
        ")\n",
        "panel[\"item_cnt_month\"] = panel[\"item_cnt_month\"].fillna(0).astype(np.float32)\n",
        "\n",
        "# Precio: si no hubo venta, dejamos NaN para poder usar “último precio observado” más adelante\n",
        "panel[\"price_mean\"] = panel[\"price_mean\"].astype(np.float32)\n",
        "\n",
        "# Variables de calendario (estacionalidad)\n",
        "panel[\"month\"] = (panel[\"date_block_num\"] % 12).astype(np.int8)\n",
        "panel[\"year\"]  = (panel[\"date_block_num\"] // 12).astype(np.int8)\n",
        "\n",
        "# Representación cíclica del mes para estacionalidad suave\n",
        "panel[\"month_sin\"] = np.sin(2*np.pi*panel[\"month\"]/12).astype(np.float32)\n",
        "panel[\"month_cos\"] = np.cos(2*np.pi*panel[\"month\"]/12).astype(np.float32)\n",
        "\n",
        "# Unimos agregados laggeados; si no existe info previa, dejamos 0\n",
        "panel = panel.merge(global_agg, on=\"date_block_num\", how=\"left\")\n",
        "panel = panel.merge(item_agg,   on=[\"date_block_num\",\"item_id\"], how=\"left\")\n",
        "panel = panel.merge(shop_agg,   on=[\"date_block_num\",\"shop_id\"], how=\"left\")\n",
        "\n",
        "for c in [\"global_mean\",\"global_sum\",\"global_pairs\",\"item_mean\",\"item_shops\",\"item_price_mean\",\"shop_mean\",\"shop_items\"]:\n",
        "    panel[c] = panel[c].fillna(0).astype(np.float32)\n",
        "\n",
        "del train, monthly, global_agg, item_agg, shop_agg, test_pairs\n",
        "gc.collect()\n",
        "\n",
        "# Precio: transformamos y creamos “último precio conocido”\n",
        "# Esto evita usar cero como precio cuando no hubo venta y mantiene consistencia temporal\n",
        "p_obs = panel[\"price_mean\"].dropna()\n",
        "p999 = p_obs.quantile(0.999) if len(p_obs) else 0.0\n",
        "\n",
        "price_clip = panel[\"price_mean\"].clip(0, p999)\n",
        "panel[\"log_price_obs\"] = np.where(panel[\"price_mean\"].notna(), np.log1p(price_clip), np.nan).astype(np.float32)\n",
        "panel[\"item_log_price_mean\"] = np.log1p(panel[\"item_price_mean\"].clip(0, p999)).astype(np.float32)\n",
        "\n",
        "panel.sort_values([\"shop_id\",\"item_id\",\"date_block_num\"], inplace=True, ignore_index=True)\n",
        "g = panel.groupby([\"shop_id\",\"item_id\"], sort=False)\n",
        "\n",
        "panel[\"log_price_last\"] = g[\"log_price_obs\"].ffill()\n",
        "panel[\"log_price_last\"] = g[\"log_price_last\"].shift(1).astype(np.float32)\n",
        "\n",
        "panel[\"price_missing_last\"] = panel[\"log_price_last\"].isna().astype(np.int8)\n",
        "panel[\"log_price_last\"] = panel[\"log_price_last\"].fillna(panel[\"item_log_price_mean\"]).astype(np.float32)\n",
        "panel[\"price_gap_item\"] = (panel[\"log_price_last\"] - panel[\"item_log_price_mean\"]).astype(np.float32)\n",
        "\n",
        "# Lags del target: capturan autocorrelación y estacionalidad (lag 12)\n",
        "for lag in [1,2,3,4,5,6,12]:\n",
        "    panel[f\"cnt_lag_{lag}\"] = g[\"item_cnt_month\"].shift(lag).fillna(0).astype(np.float32)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MS5WOOZQU5q4",
        "outputId": "a7424951-986f-4813-a3cb-ad466c97cdc0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "guardado en: intermediate_data\n",
            "['test_pairs.parquet', 'meta.json', 'test_features.parquet', 'valid.parquet', 'train.parquet']\n"
          ]
        }
      ],
      "source": [
        "# Ventanas recientes (últimos 3 y 6 meses) construidas desde lags\n",
        "# Útiles para medir nivel, variabilidad e intermitencia sin usar rolling pesado\n",
        "eps = 1e-6\n",
        "l1 = panel[\"cnt_lag_1\"]; l2 = panel[\"cnt_lag_2\"]; l3 = panel[\"cnt_lag_3\"]\n",
        "l4 = panel[\"cnt_lag_4\"]; l5 = panel[\"cnt_lag_5\"]; l6 = panel[\"cnt_lag_6\"]\n",
        "l12 = panel[\"cnt_lag_12\"]\n",
        "\n",
        "panel[\"sum_3\"]  = (l1 + l2 + l3).astype(np.float32)\n",
        "panel[\"mean_3\"] = (panel[\"sum_3\"] / 3.0).astype(np.float32)\n",
        "panel[\"max_3\"]  = np.maximum.reduce([l1.values, l2.values, l3.values]).astype(np.float32)\n",
        "panel[\"nz_3\"]   = ((l1>0).astype(np.int8) + (l2>0).astype(np.int8) + (l3>0).astype(np.int8)).astype(np.int8)\n",
        "\n",
        "mean_sq_3 = ((l1*l1 + l2*l2 + l3*l3) / 3.0).astype(np.float32)\n",
        "panel[\"std_3\"] = np.sqrt(np.maximum(mean_sq_3 - panel[\"mean_3\"]*panel[\"mean_3\"], 0)).astype(np.float32)\n",
        "\n",
        "panel[\"sum_6\"]  = (l1+l2+l3+l4+l5+l6).astype(np.float32)\n",
        "panel[\"mean_6\"] = (panel[\"sum_6\"]/6.0).astype(np.float32)\n",
        "panel[\"max_6\"]  = np.maximum.reduce([l1.values,l2.values,l3.values,l4.values,l5.values,l6.values]).astype(np.float32)\n",
        "panel[\"nz_6\"]   = ((l1>0)+(l2>0)+(l3>0)+(l4>0)+(l5>0)+(l6>0)).astype(np.int8)\n",
        "\n",
        "mean_sq_6 = ((l1*l1+l2*l2+l3*l3+l4*l4+l5*l5+l6*l6) / 6.0).astype(np.float32)\n",
        "panel[\"std_6\"] = np.sqrt(np.maximum(mean_sq_6 - panel[\"mean_6\"]*panel[\"mean_6\"], 0)).astype(np.float32)\n",
        "\n",
        "panel[\"rate_6\"] = (panel[\"nz_6\"] / 6.0).astype(np.float32)\n",
        "panel[\"mean_nonzero_6\"] = (panel[\"sum_6\"] / (panel[\"nz_6\"].astype(np.float32) + eps)).astype(np.float32)\n",
        "panel[\"interval_6\"] = (6.0 / (panel[\"nz_6\"].astype(np.float32) + eps)).astype(np.float32)\n",
        "\n",
        "panel[\"active_1\"] = (l1 > 0).astype(np.int8)\n",
        "panel[\"dead_6\"]   = (panel[\"nz_6\"] == 0).astype(np.int8)\n",
        "\n",
        "panel[\"trend_1_3\"]  = (l1 - l3).astype(np.float32)\n",
        "panel[\"trend_1_12\"] = (l1 - l12).astype(np.float32)\n",
        "panel[\"ratio_1_12\"] = (l1 / (l12 + eps)).astype(np.float32)\n",
        "\n",
        "# Recency: cuántos meses han pasado desde la última venta\n",
        "sale_month = panel[\"date_block_num\"].where(panel[\"item_cnt_month\"] > 0, np.nan)\n",
        "last_sale_inclusive = sale_month.groupby([panel[\"shop_id\"], panel[\"item_id\"]]).ffill()\n",
        "panel[\"last_sale_month\"] = last_sale_inclusive.groupby([panel[\"shop_id\"], panel[\"item_id\"]]).shift(1)\n",
        "\n",
        "panel[\"recency\"] = (panel[\"date_block_num\"] - panel[\"last_sale_month\"]).fillna(99).clip(0, 99).astype(np.int16)\n",
        "panel.drop(columns=[\"last_sale_month\"], inplace=True)\n",
        "\n",
        "# Historial acumulado: ayuda a separar pares nuevos vs pares ya activos\n",
        "panel[\"sold\"] = (panel[\"item_cnt_month\"] > 0).astype(np.int8)\n",
        "panel[\"sold_cum\"] = g[\"sold\"].cumsum().astype(np.int16)\n",
        "panel[\"sold_cum_lag1\"] = g[\"sold_cum\"].shift(1).fillna(0).astype(np.int16)\n",
        "\n",
        "panel[\"sales_cum\"] = g[\"item_cnt_month\"].cumsum().astype(np.float32)\n",
        "panel[\"sales_cum_lag1\"] = g[\"sales_cum\"].shift(1).fillna(0).astype(np.float32)\n",
        "panel[\"log_sales_cum_lag1\"] = np.log1p(panel[\"sales_cum_lag1\"]).astype(np.float32)\n",
        "\n",
        "panel[\"never_sold_before\"] = (panel[\"sold_cum_lag1\"] == 0).astype(np.int8)\n",
        "\n",
        "# Split temporal: entrenamos hasta 32, validamos en 33 y generamos features para 34\n",
        "train_df = panel[panel[\"date_block_num\"] <= max_block - 1].copy()\n",
        "valid_df = panel[panel[\"date_block_num\"] == max_block].copy()\n",
        "test_df  = panel[panel[\"date_block_num\"] == test_block].copy()\n",
        "\n",
        "y_train = train_df[\"item_cnt_month\"].astype(np.float32)\n",
        "y_valid = valid_df[\"item_cnt_month\"].astype(np.float32)\n",
        "\n",
        "feature_cols = [\n",
        "    \"date_block_num\",\"month\",\"year\",\"month_sin\",\"month_cos\",\"shop_id\",\"item_id\",\n",
        "    \"global_mean\",\"global_sum\",\"global_pairs\",\n",
        "    \"item_mean\",\"item_shops\",\n",
        "    \"shop_mean\",\"shop_items\",\n",
        "    \"log_price_last\",\"item_log_price_mean\",\"price_gap_item\",\"price_missing_last\",\n",
        "    \"cnt_lag_1\",\"cnt_lag_2\",\"cnt_lag_3\",\"cnt_lag_4\",\"cnt_lag_5\",\"cnt_lag_6\",\"cnt_lag_12\",\n",
        "    \"sum_3\",\"mean_3\",\"std_3\",\"max_3\",\"nz_3\",\n",
        "    \"sum_6\",\"mean_6\",\"std_6\",\"max_6\",\"nz_6\",\n",
        "    \"rate_6\",\"mean_nonzero_6\",\"interval_6\",\n",
        "    \"active_1\",\"dead_6\",\n",
        "    \"recency\",\"trend_1_3\",\"trend_1_12\",\"ratio_1_12\",\n",
        "    \"sold_cum_lag1\",\"log_sales_cum_lag1\",\"never_sold_before\",\n",
        "]\n",
        "\n",
        "X_train = train_df[feature_cols]\n",
        "X_valid = valid_df[feature_cols]\n",
        "X_test  = test_df[feature_cols]\n",
        "\n",
        "# Guardado de base intermedia: deja el modelado más limpio y reproducible\n",
        "OUT_DIR = \"data/prep\"\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "train_out = X_train.copy()\n",
        "train_out[\"y\"] = y_train.values\n",
        "\n",
        "valid_out = X_valid.copy()\n",
        "valid_out[\"y\"] = y_valid.values\n",
        "\n",
        "test_out = X_test.copy()\n",
        "\n",
        "test_meta = test_df[[\"shop_id\",\"item_id\"]].copy()\n",
        "test_meta.to_parquet(f\"{OUT_DIR}/test_pairs.parquet\", index=False)\n",
        "\n",
        "train_out.to_parquet(f\"{OUT_DIR}/train.parquet\", index=False)\n",
        "valid_out.to_parquet(f\"{OUT_DIR}/valid.parquet\", index=False)\n",
        "test_out.to_parquet(f\"{OUT_DIR}/test_features.parquet\", index=False)\n",
        "\n",
        "meta = {\n",
        "    \"feature_cols\": feature_cols,\n",
        "    \"max_block\": int(max_block),\n",
        "    \"test_block\": int(test_block),\n",
        "}\n",
        "with open(f\"{OUT_DIR}/meta.json\", \"w\") as f:\n",
        "    json.dump(meta, f, indent=2)\n",
        "\n",
        "print(\"guardado en:\", OUT_DIR)\n",
        "print(os.listdir(OUT_DIR))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J8cmbdfxU5s-"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
